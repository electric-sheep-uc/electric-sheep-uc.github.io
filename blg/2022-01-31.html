<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en" dir="ltr">
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <meta name="keywords" content="Electric, Sheep, RoboCup, Humanoid" />
  <title>Electric Sheep</title>
  <style>
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    span.underline{text-decoration: underline;}
    div.column{display: inline-block; vertical-align: top; width: 50%;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
  </style>
  <link rel="stylesheet" href="/media/dan/DATA/Documents/Projects/nz-dev/website/www/style.css" />
</head>
<body>
<p><img src="/img/logo-walk.gif" /></p>
<ul class="n">
<li class="n">
<a class="n" href="/index.html#">Home</a>
</li>
<li class="n">
<a class="n" href="/index.html#blogs">Blogs</a>
</li>
<li class="n">
<a class="n" href="/index.html#about-team">About Team</a>
</li>
<li class="n">
<a class="n" href="/index.html#team-members">Team Members</a>
</li>
<li class="n">
<a class="n" href="/index.html#achievements">Achievements</a>
</li>
<li class="n">
<a class="n" href="/index.html#releases">Releases</a>
</li>
<li class="n">
<a class="n" href="/index.html#press">Press</a>
</li>
<li class="n">
<a class="n" href="/index.html#contact-us">Contact Us</a>
</li>
<li class="n">
<a class="n" href="/rss.xml">RSS</a>
</li>
</ul>
<header id="title-block-header">
<h1 class="title">Electric Sheep</h1>
</header>
<h2 id="balance-engine">Balance Engine</h2>
<p><code>Last Modfified: 2022-01-31</code></p>
<p><strong>Note:</strong> This article is a high-level discussion of a technical nature (in comparison to other articles). We keep the discussion somewhat abstract but it may still prove difficult to follow.</p>
<p>As eluded to in the previous <a href="2021-12-19.html">general update</a>, we are making awesome progress since the last update over the Christmas period. One of the projects we will discuss today is the concept of a <em>balance engine</em> and some of the work that has happened around this.</p>
<h3 id="brief-history-of-robocup-walking">Brief History of RoboCup Walking</h3>
<p><em>In the beginning, there were robot dogs…</em></p>
<iframe src="https://www.youtube.com/embed/xXvhSE1no1w" allowfullscreen>
</iframe>
<p><em>Video: RoboCup Dog platform in Japan (2009).</em></p>
<p>Dogs are great as an initial platform - they are stable and <em>cute</em> <a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a>. Initial problems can be addressed regarding to team play, vision, communication, locomotion, etc, whilst offering fun and novel games for the public to engage with.</p>
<p><del>Unfortunately</del> At some point it was decided that in order to achieve the goal of robots vs people in 2050, they must be bipedal. In 2013, the <a href="https://robocup.herts.ac.uk/">Bold Hearts</a> decided to switch from a successful run in the simulation league and enter into the humanoid league, which consists of hardware!</p>
<p><em>Bipedal walking is hard.</em></p>
<p>Normally, for open-loop humanoid walking, we would have the open-loop walk send motor commands without any feedback. This worked well for flat surfaces with some walk engine parameter tweaking, and was appropriate in the domain space for quite some years. This in turn gave teams time to work on other advancements, such as vision and localisation.</p>
<iframe src="https://www.youtube.com/embed/AoCVVbolh7E" allowfullscreen>
</iframe>
<p><em>Video: Bold Hearts DarwinOp player using an open-loop walk engine on a flat surface (2013).</em></p>
<p>This was never the <a href="https://robocup.org/objective">end-goal</a> though, and some years ago the challenge of walking was made more difficult with the additional of artificial grass. This made the challenge of humanoid walking much more difficult. For the first year of this rule change, very few teams could walk reliably towards the ball. Of course, teams arose to the challenge and in the next year most teams could walk somewhat reliably.</p>
<iframe src="https://www.youtube.com/embed/CaZP5I9xwUw" allowfullscreen>
</iframe>
<p><em>Video: Bold Hearts (modified) DarwinOp player using an open-loop walk engine on artificial grass (2018).</em></p>
<p>As can be seen, the Bold Hearts and Electric Sheep teams (amongst others) have utilized open-loop walk engines to achieve limited stability walking on artificial grass. Typically this would involve tweaking per-robot walking parameters for the particular field we intend to play on. We found that as the robots became larger and their centre of mass was heightened, the issue of stability became much more difficult.</p>
<iframe src="https://www.youtube.com/embed/Y9JFQmkmr_A" allowfullscreen>
</iframe>
<p><em>Video: Electric Sheep player using an open-loop walk engine on artificial grass (2020).</em></p>
<p>As some teams find moderate success in continuing to tweak their walk parameters, other teams turned to tried-and-true existing methods such as <a href="https://en.wikipedia.org/wiki/Zero_moment_point">zero moment point</a> (ZMP). ZMP is quite an old well-tested approach and makes the assumption that you are able to calculate centre of pressure (CoP), which can then be abstracted to centre of mass (CoM), which is projected to be always within the ‘support polygon’ (an area defined by the placement of the feet). ZMP works well, and in theory could allow for behaviours such as walking, running, and even jumping - although there has so far been limited success in these behaviours (at least within the league).</p>
<h3 id="challenges">Challenges</h3>
<p>There are several challenges we face in the RoboCup humanoid league that differentiate us from other research approaches:</p>
<ul>
<li><strong>Real-time</strong> - One of the major challenges RoboCup teams face is that this problem of walking must be solved live, autonomously, on the robot itself. Typically the computation resembles something like a modern Raspberry Pi due to size, weight and power requirements of specific platforms. Many research approaches will use tonnes of computation outside of the robot itself, a luxury we do not have.</li>
<li><strong>Objective</strong> - Maintaining balance whilst doing some walk behaviour is cool, but not in itself useful. The goal of our agents is not to balance a walk, but actually to play football. Therefore it is not enough for them to simply be stable, they must also be achieving their main objective.</li>
<li><strong>Environment</strong> - Our robots are not operating in some well known, well tested lab - they instead operate on a football pitch made of artificial grass, unknown until the week of the competition. Teams have just a few days to calibrate their robots, fix any issues and then play competition matches.</li>
</ul>
<p>Going further, ZMP only really solves behaviours where a support polygon can be well defined. What if, for example, you wanted to do a flip, perform actions on uneven or unknown terrain, etc? Modified versions of ZMP could in theory handle much more complex scenarios, but these solutions become more complex and much harder to define.</p>
<h3 id="a-new-approach">A New Approach</h3>
<p>What we are beginning to ask for is a <em>motion engine</em>, an engine that can solve arbitrarily difficult motion tasks <a href="#fn2" class="footnote-ref" id="fnref2" role="doc-noteref"><sup>2</sup></a>. This remains the goal of future work, so for now we work on a subset of this problem, which is an <em>adaptive balance engine</em> (ABE).</p>
<p>The intention of ABE is to take the suggestion of an open-loop walk engine, adapt it in a way that provides stability, and then send the motor commands. This does not rely on foot sensors, we do not provide any parameters to the walk engine and <em>theoretically</em> we are not bound by the idea of a support polygon, allowing for momentary instability if required.</p>
<p>We intend to publish more details about this approach at a later date.</p>
<h3 id="initial-results">Initial Results</h3>
<p>Our initial experiments were conducted using the <a href="https://gym.openai.com/envs/CartPole-v1/">OpenAI Gym cartpole problem</a>, where the agent has the ability to select <code>left</code> or <code>right</code> in each time step depending on some observed state, which includes the cart position, velocity, pole angle and pole velocity. Simulations end when the agent falls outside of some defined bounds.</p>
<figure>
<img src="2022-01-31/cartpole.png" alt="" /><figcaption>OpenAI Gym cartpole simulation</figcaption>
</figure>
<p>Other approaches <a href="#fn3" class="footnote-ref" id="fnref3" role="doc-noteref"><sup>3</sup></a>, mostly consisting of <a href="https://gym.openai.com/envs/CartPole-v0/">reinforcement learning</a> (RL) are slower to learn than our ABE approach. Most RL approaches appear to be based on <a href="https://deepmind.com/research/open-source/dqn">DeepMind’s DQN model</a> from 2015. Our approach is somewhat more computationally expensive, but yields very competitive results.</p>
<figure>
<img src="2022-01-31/scores.png" alt="" /><figcaption>Preliminary results of our algorithm</figcaption>
</figure>
<p>As you can see, it takes approximately 40 experiments for the agent to ‘solve’ the problem maximally with a consistent score of 500 <a href="#fn4" class="footnote-ref" id="fnref4" role="doc-noteref"><sup>4</sup></a>.</p>
<p><strong>Note:</strong> Due to the implementation, there is a 1% chance that the agent takes a random action. This is for the purpose of training.</p>
<h3 id="further-work">Further Work</h3>
<p>With the initial results showing promise, we now move into the <a href="https://gitlab.com/boldhearts">humanoid simulation environment created by the Bold Hearts</a>. Their platform is based on <a href="https://arxiv.org/abs/1907.00282">ROS2</a>, which offers some nice abstractions and allows for code sharing. This allows us to flesh out the concept whilst minimizing damage to real hardware, as well as offering the ability to pre-train the algorithm and minimize time spent on hardware.</p>
<figure>
<img src="2022-01-31/simulation.png" alt="" /><figcaption>Gazebo simulation environment</figcaption>
</figure>
<p>(All going well) Going forwards, we intend to explore this research further with the intention of deploying it in Bangkok, Thailand, for the <a href="https://2022.robocup.org/">2022 RoboCup World Cup</a>.</p>
<section class="footnotes" role="doc-endnotes">
<hr />
<ol>
<li id="fn1" role="doc-endnote"><p>Aesthetically pleasing robots are quite important, especially as by design these competitions are conducted with lots of public engagement.<a href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn2" role="doc-endnote"><p>This is the subject of a high-level discussion journal paper.<a href="#fnref2" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn3" role="doc-endnote"><p>Note: We only discuss those that have released their source, as the cartpole problem is technically <a href="https://link.medium.com/47hKaTmOFmb">optimally solvable</a>.<a href="#fnref3" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn4" role="doc-endnote"><p>A score of 500 is far better than is required, the ‘win’ scenario is set to 195.<a href="#fnref4" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol>
</section>
</body>
</html>
